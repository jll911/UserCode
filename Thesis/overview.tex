\chapter{Overview}
\label{over}

Little intro thing about science and stuff -- my story?
short history of particle physics?
quantum mech, cosmic ray detection with bubble chambers, etc, 
move on to accelerators
talk a little about proton interactions, 
Z boson and history, decay and detecting electrons, history of electrons?
Z important to LHC

maybe have all this history and the random definitions together 

%   * particles?  although that's theory intro (but need SOME particle-specific stuff) 
%ref ch 2 -- or wherever end up putting standard model section, maybe move to ch 1!
some kind of short little intro, motivate need to define those following terms,
want to talk about Z and why important, motivations

(The full set of particles and their interactions will be more fully 
developed in Ch.~\ref{theory}.)

   * ``high-energy''
``High-energy'' physics refers to modern particle physics. 
In the beginnings of particle physics, 
the available accelerators operated at much lower energies.  
Low-energy accelerators are still used in nuclear physics 
and aid in materials physics and biophysics studies. 
However, to probe the fundamental interactions between particles, 
today's accelerators use much higher energies.  

TACK THE DEFINITIONS ONTO THE END OF WHATEVER THE PREVIOUS 
(INTRODUCTORY) PARAGRAPH WAS

\section{Terms in particle physics, technical stuff}

%the practical purpose of MC -- can simulate all stages of gen/sim/reco/etc and compare 
%everything step-by-step with data, as well as of course getting some quantities 
%that require extra knowledge, like acceptance (and predicting efficiencies, rates, etc)
%HA, that sounds like a few of those things in the pythia manual intro!  and I came 
%up with them myself!  

%glossary? (explanatory text, with true glossary in appendix?)  

%Introductory terminology?  put terminology section in beginning?

   * ``kinematic'' 
In the following pages, much will be described by the word 
``kinematic'' or ``kinematics''.  
This refers to the properties of position or motion.  
So, ``kinematic criteria'' means selections applied according to 
quantities such as momentum or angle.  



%   * statistical and systematic uncertainties or errors

   * ``phase space''! 
``Phase space'' refers to the collection of total 
possible values for a set of quantities.  
A given system is represented by one set of 
values out of that collection.  
%Direction (in three dimensions)   % NOT ACTUALLY TRUE!!!
%plus speed or energy define a 
%four-dimensional phase space 
%for a particle's kinematic quantities.  
For some calculations it is necessary to include 
contributions from the entire phase space, 
for example integrating over all possible 
angles for a particle's direction.  

   * events
In particle physics, an ``event'' is a particle interaction 
that has been captured and recorded by the detector.  
%   * signal, background.  
In general, %events that contribute to the specific process     
events caused by the specific process     
being studied are termed ``signal,'' 
while any events 
%that do not contribute 
from other sources 
are called ``background.'' 
A significant part of any analysis is designing 
criteria that select signal events while 
rejecting background events, 
so that the analysis focuses only on data containing 
that process.  
The number of events for a given signal can be used 
to calculate quantities of interest, 
for example how often that process  
occurs relative to others.  

\section{Anatomy of an Event}
%Like, what actually happens!

this section sets the context and introduces 
terminology

A proton-proton interaction begins 
with beams of protons accelerated 
in opposite directions.  
The protons are formed into ``bunches,'' 
with many, many millions of protons per bunch.  
These beams of proton bunches are directed to 
cross at the center of the detector.  
%Most such ``bunch crossings'' do not result 
%in a significant interaction.  % interaction at all? YES, DUH pileup
In an encounter between two protons, 
the fundamental interaction takes place 
between individual ``partons,'' 
which is the collective term for 
the quarks and gluons that make up the proton.  
Each ``bunch crossing'' results in 
a small number of interactions, 
the majority of which do not interact 
strongly enough to be interesting.  
However, sometimes two partons %, 
%i.e. a quark or gluon inside the proton, 
%interacts very strongly with a parton 
%from another proton.  
from separate protons interact very strongly.  
These are the types of interactions 
that are typically interesting.  
%   * ``hard'' vs ``soft''
%A ``hard'' interaction is one in which the partons 
%interact very energetically.  
An interaction in which the partons interact 
very energetically is a ``hard interaction.''  
Conceptually, the partons ``hit each other hard.''  
Hard interactions are typically detected 
by having end-product particles with 
a lot of momentum 
in the transverse direction, 
perpendicular to the protons' original 
direction of motion.  
Only in hard interactions is the original 
momentum disturbed so much; 
in ``soft,'' or low-energy, interactions, 
most of the protons' momentum 
continues in the same direction, 
down the beam-pipe.  

Oftentimes the two partons exchange 
a particle, such as a photon or gluon.  
In other cases another particle is produced, %formed, 
such as a Z boson; 
this is the scenario 
studied in this analysis.  
Particles formed in this way 
are typically heavy and therefore 
short-lived, 
decaying into lighter, more stable particles.  
This analysis studies the Z's decay into two 
electrons, 
which are the lightest charged particles 
and therefore (to conserve charge) 
do not decay.  
These decay products are what fly ``out'' 
into the detector with 
some energy and direction, 
and it is these quantities 
that are measured by the detector.  

However, additional processes may contribute 
to the signature left in the detector.  
One of the initial partons 
or final decay products 
may radiate an additional particle 
which then ends up in the detector.  
This is known as ``initial-state radiation'' (ISR) 
and ``final-state radiation'' (FSR) respectively.  
In addition, there are two ways that 
particles unrelated to the hard interaction 
may show up in the detector: 
underlying event and pileup.  
The ``underlying event'' refers to the 
interactions taking place between the 
proton remnants, 
the parts of the proton ``left over'' 
from the hard interaction.  
``Pileup'' refers to any interactions that happen 
between other protons in the bunch.  
%These are generally soft, 
%low-energy interactions.  
Statistically, at most only one hard interaction 
happens in any given bunch crossing; the rest are soft.  
Both underlying event and pileup can contribute 
energy deposits that are recorded as part of the event.  
Typically they are both fairly low-energy and 
therefore easily filtered out as background.  

%hits, reconstruction, triggering?  
%selection out of reconstructed objects

Fully-decayed, end-product 
particles leave a signature in the detector 
by interacting with its material.  
Some detector material emits light when 
particles pass through; 
in these materials, the amount of light 
is proportional to the energy of the particle.  
Other parts of the detector rely on an 
electric signal generated 
as the particle passes by.  
%A series of these signals, close together in space, 
%can be linked together
These particle interactions with the detector 
are collectively known as ``hits.''  
In the process of reconstruction, 
hits are linked together to 
follow the path of the particle that caused them.  
For example, a series of hits in the tracker 
could show the trajectory of a charged particle 
as it passed through.  
The curvature of the trajectory could be measured 
and turned into a value for the momentum, 
knowing the value of the magnetic field.  
This track could then be linked 
with a significant emission of light 
in the calorimeter.  
If the energy from the light 
matches the momentum from the track, 
this object is reconstructed as an electron.  
A rough, on-the-fly reconstruction 
process takes place in real time to decide 
whether or not to save the event, 
%which is 
called triggering.  
Saved events undergo a more thorough 
reconstruction of their detector signals later, 
since this more thorough version 
takes too long to do in real time.  
However, not all objects reconstructed as 
a given particle are actually due to 
a real particle of that type 
passing through the detector.  
Some reconstructed objects are ``fakes.''  
These fakes are typically selected out 
by more stringent criteria on various 
particle properties. %, 
However, this selection is done at the analysis level, 
not during reconstruction.  

\section{Measurement of Cross Section}
\label{over:xsec}

%   * cross section!
The cross section, the quantity being calculated in this analysis, 
is such a measure of ``how often things happen.''  % REWORD TO HAVE IT NOT RIGHT AFTER ``EVENT''
However, it's not measured as a rate (occurrences per unit time), 
it's measured as a cross-sectional area 
and represents the probability of the given interaction occurring.  
An analogy may be made to trying to hit a target with a tennis ball.  
The bigger the target is, the more likely you will be able to hit it.  
The sizes of both objects matter: 
a trajectory that would cause a tennis ball to just miss the target 
would cause a basketball to clip the edge, 
solely because of the basketball's larger size.  
Therefore ``cross section'' may be more precisely defined as the 
effective cross-sectional area of the target, 
taking into account the sizes of both the target and the projectile.  
When both the target and projectile are particles, %such as protons, 
they may interact ``at a distance,'' that is, without ``touching'' each other, 
through the fundamental forces.  
(For example, electrons are thought to be point particles 
and therefore have no spatial extent, 
but they still attract and repel other particles 
through the electromagnetic force.) 
This interaction-at-a-distance increases the effective cross section.  
An interaction involving two particles that 
interact with each other very strongly has a large cross section.  
The cross section depends on the strength of the force between them.  
%FORMULA AND EXPLANATION HERE??

According to the definition, ``interaction cross section'' applies only to 
the particles doing the colliding.  
However, a cross section is usually associated with the entire process, 
such as (in this case) 
$ q\bar{q} \rightarrow Z/ \gamma^{*} \rightarrow e^{+} e^{-} $.  %include ggF?? or other methods of Z prod?? put all relevant feynman diagrams in theory section...
Here, the number calculated as the cross section takes into account 
only those events where a \Zg is formed, 
as well as the fact that only some of those events decay into electrons.  
The fraction of events that decay to a certain final state is known as 
the branching ratio, abbreviated BR.  
When it is not explicitly mentioned along with the cross section 
for a given final state, it is understood to be included.  
Adding up the cross sections for all of these possible interactions 
would give the full proton-proton interaction cross section.  

The cross section $\sigma$ is related to the event count $n$ by 
\[
n = \sigma \times \mathcal{ L }
\]
$\mathcal{ L }$ in this equation is the ``luminosity,'' 
a measure of the number of proton collisions.  
Two types of luminosity are spoken of in particle physics: 
instantaneous luminosity and integrated luminosity.  
Instantaneous luminosity, denoted here by $L$, 
refers to the rate of potential proton interactions.  
Specifically, it is defined as the number of protons 
passing through a given area in a given amount of time.  
If the same number of protons are squeezed into a smaller area, 
the instantaneous luminosity is higher; 
the protons in the colliding beams are more likely to interact.  
This is analogous to trying to walk through a room with many 
other people in it; 
you are much more likely to bump into people in a small, crowded room 
than a large room in which the people are much more spread out.  
% is luminosity measured per beam or what??
% how is it measured otherwise??
% how much the beams overlap affect it...
Integrated luminosity, or $\mathcal{ L }$ here, 
is the instantaneous luminosity accumulated 
over a definite period of time, 
effectively the total number of protons 
that have passed through a unit of area.  
It is a measure of the total amount of data gathered.  
The luminosity in the above equation refers to 
the integrated luminosity.  
Essentially, the total amount of data (the luminosity) 
times the likelihood a specific interaction will happen 
(the cross section) 
gives you the total number of events of that type 
that have happened (the event count, $n$).  
In practice this formula must be modified 
to account for the natural limitations of the detector: 
Two new factors, $A$ and $\epsilon$, must be introduced.  
$A$, the ``acceptance,'' accounts for the fact 
that the detector cannot be designed in a way 
that allows it to see every possible particle.  
In particular, any particles that continue 
in the direction of the proton beam will be lost -- 
the presence of the beam pipe precludes 
detector material in that direction.  
%In addition, due to the large magnetic field 
%used within the detector, 
%a particle with a low enough energy may 
%spiral around inside, not actually hitting 
%the calorimeter.  
The value of the acceptance is the fraction 
of the events that can theoretically 
be seen by the detector, %.  
often defined in terms of %as %to be within 
a region of kinematic phase space: % PUT KINEMATIC AND PHASE SPACE DEFS BEFORE THIS
``above energy X and within angular constraints Y.''
For simplicity's sake, 
these constraints are typically chosen to include 
only regions of the detector 
and particle energies 
for which the particles of interest can be well-reconstructed.  
The ``efficiency,'' $\epsilon$, 
takes into account the fact that 
even for particles that leave a definite 
signature in the detector, 
they may still not be recorded as such.  
High efficiency is a primary goal of any 
experiment, 
but the sources of inefficiency can never be 
completely eliminated.  
The efficiency is often broken down into 
efficiencies of the individual steps: 
\[
\epsilon = \epsilon_{ trig } \times \epsilon_{ reco } \times \epsilon_{ sel }
\]
The individual efficiencies correspond to 
triggering, reconstruction, and selection.  % DEFINE THESE BEFOREHAND
The boundary between what is considered 
for the acceptance versus for the efficiency 
is somewhat fluid: 
failing to record a particle 
with a very low energy may be 
considered an issue of acceptance 
%defined as being outside the acceptance 
(because the detector is not designed 
for such small energies) 
or a matter of efficiency 
(because though the particle left 
a signature in the detector, 
it was not reconstructed).  
It is merely a matter of definition, 
and in the end result makes no difference.  

The inclusion of acceptance and efficiency 
turn the previous expression 
of event count and cross section into 
\[
n = \sigma \times \mathcal{ L } \times \epsilon \times A
\]
The number of events actually seen ($n$) is reduced 
by the factors accounting for the detector limitations.  
In order to calculate the cross section $\sigma$ 
(including the branching ratio) 
of the 
$ q\bar{q} \rightarrow Z/ \gamma^{*} \rightarrow e^{+} e^{-} $ 
interaction, 
which is the quantity this analysis aims to get, 
the equation must be rearranged into 
\[
\sigma_{ Z } \times \textrm{ BR }_{ Zee } = \frac{ n_{ Zee } }{ \mathcal{ L } \times \epsilon \times A}
\]
Now $\sigma \times \textrm{ BR }$ is expressed 
in terms of other quantities which 
can be measured or calculated.  
This equation is the heart of this analysis.  
The ``meat'' of the analysis is then 
measuring the quantities that combine to 
make up the cross section, 
and putting it all together.  


\section{Reference Frame and Coordinates}

%   * center of momentum reference frame

For some high-energy physics experiments, 
there is a choice of several reference 
frames that can be used for measurement, 
each with their own benefits.  
However, in the case of proton-proton collisions, 
the logical reference frame for measurements is 
the frame at rest with respect to the detector, 
the ``lab frame,'' 
because it is the same as the 
proton-proton center of momentum frame.  
Therefore all measurements are done 
in the lab frame.  

%   * eta/y, phi

A particular set of coordinates is often used to describe 
the direction of outgoing or intermediate particles.  
The direction of the incoming particles defines an axis, 
the beam axis.  
The azimuthal angle, measured around this axis 
and analogous to longitude on the earth's surface, 
is labeled $\phi$.  
The angle along the axis, the polar angle 
(analogous to latitude), 
is labeled by $\theta$.  
However, it is much more common to measure this 
angle in terms of pseudorapidity, $\eta$, 
which is given as a function of $\theta$:
\[
\eta = -\ln \left[ \tan \left( \frac{\theta}{2}\right) \right]
\]
$\eta$ is preferred because of its relation to another quantity, 
rapidity, $y$, which is a function of the particle's 
energy and momentum:
\[
y = \frac{1}{2} \ln \left( \frac{E+p_L}{E-p_L} \right)
\]
where $p_L$ is the longitudinal component of the 
particle's momentum (the component parallel to the beam axis).  
% WON'T DO COMPOSITION OF VECTORS
Rapidity is useful when dealing with relativistic speeds, 
such as those at which the particles typically travel.  
When viewed from separate reference frames that are moving 
at relativistic speeds with respect to each other, 
a particle's speed, direction, and energy appear to be different.  
However, rapidity has special status in that the 
difference in rapidity 
between two particles does not change 
when the reference frame is changed.  
A particle's rapidity can be approximated by the 
pseudorapidity if it is very light or 
traveling very fast 
(pseudorapidity is identical to rapidity 
if the particle has zero mass, 
in which case it is also 
moving at the speed of light).  
In addition, outgoing particles tend to be 
distributed uniformly in terms of rapidity, 
as opposed to the polar angle $\theta$, 
which does not enjoy the same uniform distribution. 
Since rapidity itself is not a measure of angle, 
pseudorapidity is used as the coordinate.  
Rapidity is calculated in cases 
where the particle of interest may be heavy 
and may not have a high speed, 
for example the Z boson examined in this analysis.  

%\section{General Analysis Software}
\section{General Analysis Tools} % changed from ``considerations''

   * histogram?  errors? (stat/syst) etc?

MAYBE COME UP WITH SOMEWHERE BETTER TO PUT THIS, someplace relevant 
(talking about a data method vs MC or something)
mention MC here, anyhow
   * ``data-driven'' stuff?  need for efficiency, but also systs??
The term ``data-driven'' is used to describe an analysis method 
that uses only real data, taken with the detector, 
instead of relying on simulated data.  
The purpose of using a data-driven method is to 
eliminate the possibility of a physics result 
being affected by an error or inaccuracy 
in the simulation itself.  
Since some quantities, such as efficiency, 
are much easier to measure using simulated data, 
devising data-driven methods to measure those quantities 
is an important and potentially challenging 
part of analysis.  

\subsection{Software}
%   * ROOOOOOOOOT!  other software, like CMSSW? yes

% root.cern.ch duh

% have no idea how to reference CMSSW -- workbook??

This analysis made use of many software packages 
to perform specific functions within 
the process of analyzing the data.  
Most of the software will be explained 
in the chapter to which each piece is particularly 
relevant.  
However, two programs in particular 
served many purposes 
throughout the whole of the analysis and 
should therefore be mentioned separately.  
%Two software programs in particular were 
%used in this analysis.  

The CMS Software (CMSSW) framework is 
the collaboration-developed software 
used for many aspects of CMS operation and use.  
It encompasses data-taking, reconstruction, 
simulation, and analysis.  
% what else to say?  

ROOT is a general data analysis package, 
written in C++, 
and developed and maintained at CERN. 
It is widely used in the field of 
experimental particle physics.  
ROOT implements many tools and functions 
necessary to various types of analysis, 
such as histograms, fitting, 
and statistics.  
CMSSW can interface with ROOT, 
providing access to ROOT's %wide 
%range of 
capabilities within a CMSSW 
analysis setting.  

